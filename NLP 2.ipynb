{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 2 : Neural Embeddings, Text Classification, Text Generation\n",
    "\n",
    "\n",
    "To use statistical classifiers with text, it is first necessary to vectorize the text. In the first practical session we explored the **bag of word** model which is not the most accurate. \n",
    "\n",
    "State of the art methods uses language models to vectorize the text before classification.\n",
    "\n",
    "## Classic word embeddings\n",
    "\n",
    "- [Word2Vec](https://arxiv.org/abs/1301.3781)\n",
    "- [Glove](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "\n",
    "## bleeding edge (only for reference)\n",
    "\n",
    "- [UMLFIT](https://arxiv.org/abs/1801.06146)\n",
    "- [ELMO](https://arxiv.org/abs/1802.05365)\n",
    "- [BERT](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "\n",
    "In this second practical session, we mainly explore what can be done with classical word embeddings obtained from `word2vec`\n",
    "\n",
    "\n",
    "\n",
    "##  Loading data (same as nlp 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This is a film that the mainstream market will probably never be able to access as it doesn\\'t exactly give the viewer easy watching. The story about troubled Spike and his friend Heaton is not exactly a Friday night film yet it has its own unique edge and I found that it was entertaining. There are moments of brilliance given that the film was shot on such a low budget, such as when Spike inhales the aerosol. However I did not really understand the relationship between Spike and Heaton and to be honest it made me spend most of the film trying to work it out. And also I did not like the fact that most of the film is spent with the two friends talking and not really much \"action\". It is a small film that is complex to watch and that is what makes it appealing.', 1)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from os.path import split as pathsplit\n",
    "\n",
    "dir_train = \"dataset/aclImdb/train/\"\n",
    "dir_test = \"dataset/aclImdb/test/\"\n",
    "\n",
    "train_files = glob.glob(dir_train+'pos/*.txt') + glob.glob(dir_train+'neg/*.txt')\n",
    "test_files = glob.glob(dir_test+'pos/*.txt') + glob.glob(dir_test+'neg/*.txt')\n",
    "\n",
    "\n",
    "def get_polarity(f):\n",
    "    \"\"\"\n",
    "    Extracts polarity from filename:\n",
    "    0 is negative (< 5)\n",
    "    1 is positive (> 5)\n",
    "    \"\"\"\n",
    "    _,name = pathsplit(f)\n",
    "    if int(name.split('_')[1].split('.')[0]) < 5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def open_one(f):\n",
    "    \n",
    "    polarity = get_polarity(f)\n",
    "    \n",
    "    with open(f,\"r\") as review:\n",
    "        text = \" \".join(review.readlines()).strip()\n",
    "    \n",
    "    return (text,polarity)\n",
    "\n",
    "print(open_one(train_files[0]))\n",
    "\n",
    "train = [open_one(x) for x in train_files] #contains (text,pol) couples\n",
    "test = [open_one(x) for x in test_files]   #contains (text,pol) couples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: Quick Recap\n",
    "\n",
    "**[Word2Vec](https://arxiv.org/abs/1301.3781) is two distinct language models, optimized to quickly learn word vectors**\n",
    "\n",
    "\n",
    "given a random text: `i'm taking the dog out for a walk`\n",
    "\n",
    "\n",
    "\n",
    "### (a) Continuous Bag of Word (CBOW)\n",
    "    -  predicts a word given a context\n",
    "    \n",
    "maximizing `p(dog | i'm taking the ___ out for a walk)`\n",
    "    \n",
    "### (b) Skip-Gram (SG)               \n",
    "    -  predicts a context given a word\n",
    "    \n",
    " maximizing `p(i'm taking the out for a walk | dog)`\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: train (or load) a language model (word2vec)\n",
    "\n",
    "Gensim has one of [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) fastest implementation.\n",
    "\n",
    "\n",
    "### Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-07 17:33:32,703 : INFO : collecting all words and their counts\n",
      "2018-11-07 17:33:32,704 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-11-07 17:33:33,452 : INFO : PROGRESS: at sentence #10000, processed 2377615 words, keeping 155725 word types\n",
      "2018-11-07 17:33:34,197 : INFO : PROGRESS: at sentence #20000, processed 4691609 words, keeping 243773 word types\n",
      "2018-11-07 17:33:34,579 : INFO : collected 280617 word types from a corpus of 5844680 raw words and 25000 sentences\n",
      "2018-11-07 17:33:34,580 : INFO : Loading a fresh vocabulary\n",
      "2018-11-07 17:33:34,975 : INFO : min_count=5 retains 49345 unique words (17% of original 280617, drops 231272)\n",
      "2018-11-07 17:33:34,976 : INFO : min_count=5 leaves 5517507 word corpus (94% of original 5844680, drops 327173)\n",
      "2018-11-07 17:33:35,148 : INFO : deleting the raw counts dictionary of 280617 items\n",
      "2018-11-07 17:33:35,153 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2018-11-07 17:33:35,154 : INFO : downsampling leaves estimated 4268608 word corpus (77.4% of prior 5517507)\n",
      "2018-11-07 17:33:35,155 : INFO : estimated required memory for 49345 words and 100 dimensions: 64148500 bytes\n",
      "2018-11-07 17:33:35,370 : INFO : resetting layer weights\n",
      "2018-11-07 17:33:35,967 : INFO : training model with 3 workers on 49345 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-07 17:33:36,976 : INFO : PROGRESS: at 4.91% examples, 1044188 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:37,978 : INFO : PROGRESS: at 9.73% examples, 1043764 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:38,985 : INFO : PROGRESS: at 14.77% examples, 1051430 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:39,986 : INFO : PROGRESS: at 19.85% examples, 1055191 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:40,987 : INFO : PROGRESS: at 24.82% examples, 1056276 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:41,991 : INFO : PROGRESS: at 29.67% examples, 1054740 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:42,993 : INFO : PROGRESS: at 34.61% examples, 1054016 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:43,994 : INFO : PROGRESS: at 39.46% examples, 1050081 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:45,000 : INFO : PROGRESS: at 43.40% examples, 1025589 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:46,009 : INFO : PROGRESS: at 47.31% examples, 1007916 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-07 17:33:47,012 : INFO : PROGRESS: at 50.80% examples, 983142 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:48,022 : INFO : PROGRESS: at 54.95% examples, 974389 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-07 17:33:49,022 : INFO : PROGRESS: at 59.95% examples, 980361 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:50,022 : INFO : PROGRESS: at 64.78% examples, 984131 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:51,023 : INFO : PROGRESS: at 69.67% examples, 989011 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:52,029 : INFO : PROGRESS: at 73.78% examples, 981356 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:53,031 : INFO : PROGRESS: at 78.59% examples, 983317 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:54,035 : INFO : PROGRESS: at 83.50% examples, 986485 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:55,044 : INFO : PROGRESS: at 88.01% examples, 985996 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:56,050 : INFO : PROGRESS: at 92.55% examples, 984117 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-07 17:33:57,051 : INFO : PROGRESS: at 97.53% examples, 987376 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-07 17:33:57,541 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-07 17:33:57,546 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-07 17:33:57,547 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-07 17:33:57,548 : INFO : training on 29223400 raw words (21344339 effective words) took 21.6s, 989118 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "text = [t.split() for t,p in train]\n",
    "\n",
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                size=100, window=5,\n",
    "                                min_count=5, \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=0, hs=0, negative=5,\n",
    "                                cbow_mean=1,\n",
    "                                iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It's for later\n",
    "\n",
    "#from gensim.test.utils import datapath\n",
    "#w2v = KeyedVectors.load_word2vec_format(datapath('downloaded_vectors_path'), binary=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Gensim, embeddings are loaded and can be used via the [\"KeyedVectors\"](https://radimrehurek.com/gensim/models/keyedvectors.html) class\n",
    "\n",
    "> Since trained word vectors are independent from the way they were trained (Word2Vec, FastText, WordRank, VarEmbed etc), they can be represented by a standalone structure, as implemented in this module.\n",
    "\n",
    ">The structure is called “KeyedVectors” and is essentially a mapping between entities and vectors. Each entity is identified by its string id, so this is a mapping between {str => 1D numpy array}.\n",
    "\n",
    ">The entity typically corresponds to a word (so the mapping maps words to 1D vectors), but for some models, they key can also correspond to a document, a graph node etc. To generalize over different use-cases, this module calls the keys entities. Each entity is always represented by its string id, no matter whether the entity is a word, a document or a graph node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Test learnt embeddings\n",
    "\n",
    "The word embedding space directly encodes similarities between words: the vector coding for the word \"great\" will be closer to the vector coding for \"good\" than to the one coding for \"bad\". Generally, [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) is the distance used when considering distance between vectors.\n",
    "\n",
    "KeyedVectors have a built in [similarity](https://radimrehurek.com/gensim/models /keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.similarity) method to compute the cosine similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# is great really closer to good than to bad ?\n",
    "print(\"great and good:\",w2v.wv.similarity(\"great\",\"good\"))\n",
    "print(\"great and bad:\",w2v.wv.similarity(\"great\",\"bad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Since cosine distance encodes similarity, neighboring words are supposed to be similar. The [most_similar](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.most_similar) method returns the `topn` words given a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The query can be as simple as a word, such as \"movie\"\n",
    "\n",
    "# Try changing the word\n",
    "w2v.wv.most_similar(\"movie\",topn=5) # 5 most similar words\n",
    "#w2v.wv.most_similar(\"awesome\",topn=5)\n",
    "#w2v.wv.most_similar(\"actor\",topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "But it can be a more complicated query\n",
    "Word embedding spaces tend to encode much more.\n",
    "\n",
    "The most famous exemple is: `vec(king) - vec(man) + vec(woman) => vec(queen)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What is awesome - good + bad ?\n",
    "w2v.wv.most_similar(positive=[\"awesome\",\"bad\"],negative=[\"good\"],topn=3)  \n",
    "\n",
    "#w2v.wv.most_similar(positive=[\"actor\",\"woman\"],negative=[\"man\"],topn=3) # do the famous exemple works for actor ?\n",
    "\n",
    "\n",
    "# Try other things like plurals for exemple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To test learnt \"synctactic\" and \"semantic\" similarities, Mikolov et al. introduced a special dataset containing a wide variety of three way similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = w2v.wv.accuracy(\"dataset/questions-words.txt\",case_insensitive=True)  #original semantic syntactic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The review dataset does not perform very well since it hasn't been learnt with a lot of data.\n",
    "\n",
    "\n",
    "### Try to load a pre-trained word2vec model on a much bigger dataset and redo the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4:  sentiment classification\n",
    "\n",
    "In the previous practical session, we used a bag of word approach to transform text into vectors.\n",
    "Here, we propose to try to use word vectors (previously learnt or loaded).\n",
    "\n",
    "Since we have only word vectors and that sentences are made of multiple words, we need to aggregate them.\n",
    "\n",
    "\n",
    "### (1) Vectorize reviews using word vectors:\n",
    "\n",
    "Word aggregation can be done in different ways:\n",
    "\n",
    "- Sum\n",
    "- Average\n",
    "- Min/feature\n",
    "- Max/feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# We first need to vectorize text:\n",
    "# First we propose to a sum of them\n",
    "\n",
    "\n",
    "def vectorize(text,mean=False):\n",
    "\"\"\"\n",
    "This function should vectorize one review\n",
    "\n",
    "input: str\n",
    "output: np.array(float)\n",
    "\"\"\"    \n",
    "    \n",
    "    #for word in text:\n",
    "        # do something\n",
    "            \n",
    "    return vec\n",
    "    \n",
    "\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize(text) for text,pol in train]\n",
    "X_test = [vectorize(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "#let's see what a review vector looks like.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train a classifier \n",
    "as in the previous practical session, train a logistic regression to do sentiment classification with word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Scikit Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performance should be worst than with bag of word. Sum/Mean aggregation does not work well on long reviews (especially with many frequent words). This adds a lot of noise.\n",
    "\n",
    "**(Bonus)** To have a better accuracy, we could try two things:\n",
    "- Better aggregation methods (weight by tf-idf ?)\n",
    "- A text vectorizing method such as [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html) or else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Bonus) Generate text with a recurrent neural network (Pytorch)\n",
    "\n",
    "The goal is to replicate the (famous) experiment from [Karpathy's blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "To learn to generate text, we train a recurrent neural network to do the following task:\n",
    "\n",
    "Given a \"chunk\" of text: `this is random text`\n",
    "\n",
    "the goal of the network is to predict each character in **`his is random text` ** sequentially given the following sequential input **`this is random tex`**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input ->  Output\n",
    "--------------\n",
    "T    ->    H\n",
    "H    ->    I\n",
    "I    ->    S\n",
    "S    ->    \" \"\n",
    "\" \"  ->    I\n",
    "I    ->    S\n",
    "S    ->    \" \"\n",
    "[...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load text (dataset/input.txt)\n",
    "\n",
    "Before building training batch, we load the full text in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file = unidecode.unidecode(open('dataset/input.txt').read()) #clean text => only ascii\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Helper functions:\n",
    "\n",
    "We have a text and we want to feed batch of chunks to a neural network:\n",
    "\n",
    "one chunk  A,B,C,D,E\n",
    "[input] A,B,C,D -> B,C,D,E [output]\n",
    "\n",
    "Note: we will use an embedding layer instead of a one-hot encoding scheme.\n",
    "\n",
    "for this, we have 3 functions:\n",
    "\n",
    "- One to get a random str chunk of size `chunk_len` : `random_chunk` \n",
    "- One to turn a chunk into a tensor of size `(1,chunk_len)` coding for each characters : `char_tensor`\n",
    "- One to return random input and output chunks of size `(batch_size,chunk_len)` : `random_training_set`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 28,  24,  94,  28,  17,  10,  21,  21,  94,  44],\n",
      "        [ 10,  27,  14,  32,  14,  21,  21,  73,  94,  22],\n",
      "        [ 96,  55,  17,  14,  27,  14,  94,  10,  27,  29],\n",
      "        [ 32,  14,  21,  21,  78,  94,  44,  94,  22,  30]]), tensor([[ 24,  94,  28,  17,  10,  21,  21,  94,  44,  94],\n",
      "        [ 27,  14,  32,  14,  21,  21,  73,  94,  22,  34],\n",
      "        [ 55,  17,  14,  27,  14,  94,  10,  27,  29,  94],\n",
      "        [ 14,  21,  21,  78,  94,  44,  94,  22,  30,  28]]))\n"
     ]
    }
   ],
   "source": [
    "import time, math\n",
    "\n",
    "\n",
    "#Get a piece of text\n",
    "def random_chunk(chunk_len):\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "\n",
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(1,len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[0,c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "\n",
    "#Turn a piece of text in train/test\n",
    "def random_training_set(chunk_len=200, batch_size=8):\n",
    "    chunks = [random_chunk(chunk_len) for _ in range(batch_size)]\n",
    "    inp = torch.cat([char_tensor(chunk[:-1]) for chunk in chunks],dim=0)\n",
    "    target = torch.cat([char_tensor(chunk[1:]) for chunk in chunks],dim=0)\n",
    "    \n",
    "    return inp, target\n",
    "\n",
    "print(random_training_set(10,4))  ## should return 8 chunks of 10 letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual RNN model:\n",
    "\n",
    "It should be composed of three distinct modules:\n",
    "\n",
    "- an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) (n_characters, hidden_size)\n",
    "- a [recurrent](https://pytorch.org/docs/stable/nn.html#recurrent-layers) layer (hidden_size, hidden_size)\n",
    "- a [prediction](https://pytorch.org/docs/stable/nn.html#linear) layer (hidden_size, output_size)\n",
    "\n",
    "\n",
    "=> Complete the `init` function code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_char, hidden_size, output_size, n_layers=1,rnn_cell=nn.RNN):\n",
    "        \"\"\"\n",
    "        Create the network\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.n_char = n_char\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #  (batch,chunk_len) -> (batch, chunk_len, hidden_size)  \n",
    "        self.embed = ####\n",
    "        \n",
    "        # (batch, chunk_len, hidden_size)  -> (batch, chunk_len, hidden_size)  \n",
    "        self.rnn = ####\n",
    "        \n",
    "        #(batch, chunk_len, hidden_size) -> (batch, chunk_len, output_size)  \n",
    "        self.predict = ####\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        batched forward: input is (batch > 1,chunk_len)\n",
    "        \"\"\"\n",
    "        input = self.embed(input)\n",
    "        output,_  = self.rnn(input)\n",
    "        output = self.predict(f.tanh(output))\n",
    "        return output\n",
    "    \n",
    "    def forward_seq(self, input,hidden=None):\n",
    "        \"\"\"\n",
    "        not batched forward: input is  (1,chunk_len)\n",
    "        \"\"\"\n",
    "        input = self.embed(input)\n",
    "        output,hidden  = self.rnn(input.unsqueeze(0),hidden)\n",
    "        output = self.predict(f.tanh(output))\n",
    "        return output,hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Text generation function\n",
    "\n",
    "Sample text from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(model,prime_str='A', predict_len=100, temperature=0.8):\n",
    "    prime_input = char_tensor(prime_str).squeeze(0)\n",
    "    hidden = None\n",
    "    predicted = prime_str+\"\"\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "\n",
    "    for p in range(len(prime_str)-1):\n",
    "        _,hidden = model.forward_seq(prime_input[p].unsqueeze(0),hidden)\n",
    "            \n",
    "    #print(hidden.size())\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model.forward_seq(prime_input[-1].unsqueeze(0), hidden)\n",
    "                # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        #print(output_dist)\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        #print(top_i)\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        prime_input = torch.cat([prime_input,char_tensor(predicted_char).squeeze(0)])\n",
    "\n",
    "    return predicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training loop for net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 8s (100 0%) 2.1820]\n",
      "Whose deang.\n",
      "\n",
      "QURENAARO: of thow the yous sill manaw y muven en no eneerck yecem thour And hold whan m \n",
      "\n",
      "[0m 17s (200 1%) 1.9758]\n",
      "Whir that he go you this say th with waust in to lith there extorsor and south the thim'd that prether \n",
      "\n",
      "[0m 25s (300 1%) 1.9819]\n",
      "Why uned in that in him dient--\n",
      "What sou to to mare's not the go grainas wing the pare he why,\n",
      "And wem \n",
      "\n",
      "[0m 33s (400 2%) 1.7471]\n",
      "Whey to men shee assared at the bouse is sook as at.\n",
      "\n",
      "MORD:\n",
      "Come a nen hen soale what able spectten, I \n",
      "\n",
      "[0m 41s (500 2%) 1.8626]\n",
      "Whit you be said,\n",
      "Alling head. Warrisient not of heors not do and purcle, be ding him this lord lake t \n",
      "\n",
      "[0m 50s (600 3%) 1.8683]\n",
      "Which we preather vere as and stort\n",
      "I wastay be staince; and the have more is; at brie strest I us the \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-708fba741f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#train on one chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c71ac2cd0341>\u001b[0m in \u001b[0;36mrandom_training_set\u001b[0;34m(chunk_len, batch_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c71ac2cd0341>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c71ac2cd0341>\u001b[0m in \u001b[0;36mchar_tensor\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_characters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "###Parameters\n",
    "n_epochs = 20000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 5\n",
    "lr = 0.005\n",
    "batch_size = 16\n",
    "chunk_len = 80\n",
    "\n",
    "####\n",
    "\n",
    "model = RNN(n_characters, hidden_size, n_characters, n_layers) #create model\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=lr) #create Adam optimizer\n",
    "criterion = nn.CrossEntropyLoss() #chose criterion\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "\n",
    "def train(inp, target):\n",
    "    \"\"\"\n",
    "    Train sequence for one chunk:\n",
    "    \"\"\"\n",
    "    #reset gradients\n",
    "    model_optimizer.zero_grad() \n",
    "    \n",
    "    # predict output\n",
    "    output = model(inp)\n",
    "    \n",
    "    #compute loss\n",
    "    loss =  criterion(output.view(batch_size*chunk_len,-1), target.view(-1)) \n",
    "\n",
    "    #compute gradients and backpropagate\n",
    "    loss.backward() \n",
    "    model_optimizer.step() \n",
    "\n",
    "    return loss.data.item() \n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set(chunk_len,batch_size))  #train on one chunk \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(generate(model,'Wh', 100), '\\n')\n",
    "       \n",
    "\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fabcea247b8>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRX2OgtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabfa7ae358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different temperatures\n",
    "\n",
    "Changing the distribution sharpness has an impact on character sampling:\n",
    "\n",
    "more or less probable things are sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARD I Colk find air widl,\n",
      "Give well self live\n",
      "The do pass 'blewitre of the cloe tomfise he broy't\n",
      "to doarred more, my dear.\n",
      "\n",
      "Swill they will what lister.\n",
      "\n",
      "PAENALELO:\n",
      "The a\n",
      "to he magedixie wave ouf as,\n",
      "----\n",
      "Than a had nment! a tonger; mage Shas my forrows his baud\n",
      "The that as down sour shour him consine hequentles I joy they him,\n",
      "And the vich in that Hear him gone his did the heaved youride echill ungerith\n",
      "----\n",
      "There the ster of for the have the as for or the prees with the man fate the the hear the still a for man the do you senter lord.\n",
      "\n",
      "BUCKING RICHARD III:\n",
      "This starter the my will with the for are of the c\n",
      "----\n",
      "That in shall the good where the still the to the make have the stain the day the still the stain the reather that the stain the and the stries in the stand the have of that the heart of the have the co\n",
      "----\n",
      "The stand the stand the have the stand the stand the stand the stand the stand the have the stand the stand the have the stand the have the conself the stand the stand the stand the stand the stand the \n"
     ]
    }
   ],
   "source": [
    "print(generate(model,'T', 200, temperature=1))\n",
    "print(\"----\")\n",
    "print(generate(model,'Th', 200, temperature=0.8))\n",
    "print(\"----\")\n",
    "\n",
    "print(generate(model,'Th', 200, temperature=0.5))\n",
    "print(\"----\")\n",
    "\n",
    "print(generate(model,'Th', 200, temperature=0.3))\n",
    "print(\"----\")\n",
    "\n",
    "print(generate(model,'Th', 200, temperature=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving this code:\n",
    "\n",
    "(a) Tinker with parameters:\n",
    "\n",
    "- Is it really necessary to have 100 dims character embeddings)\n",
    "- Chunk length can be gradually increased\n",
    "- Try changing RNN cell type (GRUs - LSTMs)\n",
    "\n",
    "(b) Add GPU support to go faster\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
